[scheduler]
# Time to run the scraper daily (24-hour format)
daily_run_time = 12:00
# Whether to run the scraper immediately on startup
run_immediately = true

[huggingface]
# Base URL for HuggingFace papers
base_url = https://huggingface.co/papers
# Maximum number of papers to download (0 for unlimited)
max_papers = 10
# User agent for requests
user_agent = Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36
# Request timeout in seconds
request_timeout = 30

[paths]
# Directory to save downloaded papers
download_dir = downloaded_papers
# Directory to store state information
state_dir = state
# Directory for logs
log_dir = logs

[processor]
# Whether to process existing PDFs on startup
process_existing = true

[mcp]
# URL for the MCP API
api_url = http://localhost:8000/process
# Request timeout in seconds
request_timeout = 60

[logging]
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
level = INFO
# Whether to log to console
log_to_console = true
# Whether to log to file
log_to_file = true
# Format for log messages
format = %(asctime)s - %(name)s - %(levelname)s - %(message)s
